<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speaker Extraction Demo</title>
    <link rel="stylesheet" href="style.css" />

    <!-- MathJax for LaTeX-style math -->
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>
</head>

<script>
    document.addEventListener('DOMContentLoaded', () => {
        const audioElements = document.querySelectorAll('audio');

        audioElements.forEach(audio => {
            audio.addEventListener('play', () => {
                audioElements.forEach(other => {
                    if (other !== audio) {
                        other.pause();
                        other.currentTime = 0; // Optional: rewind others to start
                    }
                });
            });
        });
    });
</script>

<body>
    <header>
        <h1>Target Speaker Extraction in a Binaural Setting using HRTFs</h1>
        <p><strong>Paper:</strong> "Binaural Target Speaker Extraction using HRTFs and a Complex-Valued Neural Network"
        </p>
    </header>

    <section id="intro" class="flex-row">
        <div class="abstract">
            <h2>Abstract</h2>
            <p>
              In this work, we aim to imitate the human ability to selectively attend to a single speaker, even in the presence of multiple simultaneous talkers.
              To achieve this, we propose a novel approach for <strong>Binaural Target Speaker Extraction (Bi-TSE)</strong> that leverages the listener’s <strong>Head-Related Transfer Function (HRTF)</strong> to isolate the desired speaker.
              Notably, our method does not rely on speaker embeddings, making it speaker-independent and enabling strong generalization across multiple speech datasets in different languages.
            </p>
            
            <p>
              We employ a fully complex-valued neural network that operates directly on the complex-valued <strong>Short-Time Fourier Transform (STFT)</strong> of the mixed audio signals.
              This deviates from conventional approaches that use spectrograms or treat the real and imaginary components of the <strong>STFT</strong> as separate real-valued inputs.
            </p>
            
            <p>
              We begin by evaluating the method in an anechoic, noise-free scenario, where it demonstrates excellent extraction performance while effectively preserving the binaural cues of the target signal.
              Next, we test a modified variant under mild reverberation conditions. This version remains robust in reverberant conditions, maintaining speech clarity, preserving source directionality, and simultaneously reducing reverberation.
            </p>

        </div>

        <div class="figures">
            <figure>
                <img src="assets/images/arc.png" alt="Block diagram of the proposed method" />
                <figcaption>
                    Figure 1: A block diagram of the proposed method, where
                    \( \boldsymbol{x}_b \) represents the mixed signal in the STFT domain,
                    \( h_d \) denotes the FFT coefficients of the HRTF for the desired speaker’s direction, and
                    \( \hat{\boldsymbol{s}}_d \) represents the extracted speech signal of the desired speaker in the
                    STFT domain.
                </figcaption>
            </figure>

            <figure>
                <img src="assets/images/convention.png" alt="Measurement system" />
                <figcaption>
                    Figure 2: Our measurement system convention, illustrating an example with two concurrent speakers
                    positioned at \( \theta_1 = 40^\circ \) (left) and \( \theta_2 = -30^\circ \) (right), with a fixed
                    elevation \( \phi \). Images sourced from: https://www.freepik.com/
                </figcaption>

            </figure>
        </div>
    </section>

    <section id="demos">
        <h2>Audio Examples and spectrograms</h2>

        <h4>Example from the From the WSJ0-CSR1 dataset in an anechoic — speaker 1 at -35°, speaker 2 at -90°</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_wsj/mix_0.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/anechoic_wsj/mix_0.wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_wsj/y_hat_1_0_az_tensor([325])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_wsj/y_hat_1_0_az_tensor([325])_elev_tensor([0]).wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_wsj/y_hat_2_0_az_tensor([270])_elev_tensor([-10]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_wsj/y_hat_2_0_az_tensor([270])_elev_tensor([-10]).wav"></audio>
                </div>
                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls src="assets/audio/anechoic_wsj/y1_0_az_tensor([325])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls
                        src="assets/audio/anechoic_wsj/y2_0_az_tensor([270])_elev_tensor([-10]).wav"></audio>
                </div>
            </div>

        </div>

        <h4>Example from the Librispeech dataset in an anechoic setting; speaker 1 at 20&deg; and speaker 2
            at
            80&deg;</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri/mix_0.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/anechoic_libri/mix_0.wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri/y_hat_1_0_az_tensor([20])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri/y_hat_1_0_az_tensor([20])_elev_tensor([0]).wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri/y_hat_2_0_az_tensor([80])_elev_tensor([0]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri/y_hat_2_0_az_tensor([80])_elev_tensor([0]).wav"></audio>

                </div>

                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls src="assets/audio/anechoic_libri/y1_0_az_tensor([20])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls src="assets/audio/anechoic_libri/y2_0_az_tensor([80])_elev_tensor([0]).wav"></audio>
                </div>
            </div>

        </div>

        <h4>Example from the Librispeech MLS French dataset in an anechoic setting; speaker 1 at 80&deg; and
            speaker 2 at 15&deg;</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri_fr/mix_472.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/anechoic_libri_fr/mix_472.wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri_fr/y_hat_1_472_az_tensor([80])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y_hat_1_472_az_tensor([80])_elev_tensor([0]).wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri_fr/y_hat_2_472_az_tensor([15])_elev_tensor([10]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y_hat_2_472_az_tensor([15])_elev_tensor([10]).wav"></audio>

                </div>

                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y1_472_az_tensor([80])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y2_472_az_tensor([15])_elev_tensor([10]).wav"></audio>
                </div>
            </div>


        </div>

        <h4>Example from the WSJ0-CSR1 dataset in a reverberant setting; speaker 1 at -25&deg; and
            speaker 2 at -75&deg;;</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/reverberant_wsj/mix_260.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/reverberant_wsj/mix_260.wav"></audio>

                </div>

                <div style="text-align: center;">
                    <img src="assets/images/reverberant_wsj/y_hat_1_260_az_tensor([335])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/reverberant_wsj/y_hat_1_260_az_tensor([335])_elev_tensor([0]).wav"></audio>

                </div>

                <div style="text-align: center;">
                    <img src="assets/images/reverberant_wsj/y_hat_2_260_az_tensor([285])_elev_tensor([-10]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/reverberant_wsj/y_hat_2_260_az_tensor([285])_elev_tensor([-10]).wav"></audio>

                </div>

                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls
                        src="assets/audio/reverberant_wsj/y1_260_az_tensor([335])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls
                        src="assets/audio/reverberant_wsj/y2_260_az_tensor([285])_elev_tensor([-10]).wav"></audio>
                </div>
            </div>
        </div>
    </section>
</body>

</html>
