<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Binaural Speaker Extraction Demo</title>
    <link rel="stylesheet" href="style.css" />

    <!-- MathJax for LaTeX-style math -->
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>
</head>

<script>
    document.addEventListener('DOMContentLoaded', () => {
        const audioElements = document.querySelectorAll('audio');

        audioElements.forEach(audio => {
            audio.addEventListener('play', () => {
                audioElements.forEach(other => {
                    if (other !== audio) {
                        other.pause();
                        other.currentTime = 0; // Optional: rewind others to start
                    }
                });
            });
        });
    });
</script>

<body>
    <header>
        <h1>Target Speaker Extraction in a Binaural Setting using HRTFs</h1>
        <p><strong>Paper:</strong> "Binaural Target Speaker Extraction using HRTFs"
        </p>
    </header>

    <section id="intro" class="flex-row">
        <div class="abstract">
            <h2>Abstract</h2>
            <p>In this work, we aim to imitate the human ability to selectively attend to a single speaker, even in the
                presence of multiple simultaneous talkers. To achieve this, we propose a novel approach for binaural
                target speaker extraction that leverages the listener’s <abbr
                    title="Head-Related Transfer Function">HRTF</abbr> to isolate the desired speaker. Notably, our
                method does not rely on speaker embeddings, making it speaker-independent and enabling strong
                generalization across multiple speech datasets in different languages.</p>

            <p>We employ a fully complex-valued neural network that operates directly on the complex-valued <abbr
                    title="Short-Time Fourier Transform">STFT</abbr> of the mixed audio signals, and compare it to a
                <abbr title="Real–Imaginary">RI</abbr>-based neural network, demonstrating the advantages of the former.
            </p>

            <p>We first evaluate the method in an anechoic, noise-free scenario, where it achieves excellent extraction
                performance while faithfully preserving the binaural cues of the target signal. We then extend the
                evaluation to reverberant conditions. Our method proves robust, maintaining speech clarity and source
                directionality while simultaneously reducing reverberation.</p>

            <p>A comparative analysis with existing binaural <abbr title="Target Speaker Extraction">TSE</abbr> methods
                demonstrates that our approach attains performance on par with competing techniques in terms of noise
                reduction and perceptual quality, while offering a clear advantage in preserving binaural cues.</p>


        </div>

        <div class="figures">
            <figure>
                <img src="assets/images/arc_1.png" alt="Block diagram of the proposed method" />
                <figcaption>
                    Figure 1: A block diagram of the proposed method, where
                    \( \boldsymbol{x}_b \) represents the mixed binaural signal in the STFT domain,
                    \( \boldsymbol{h}_{hrtf}(\theta_d,\phi_d,k) \) denotes denotes the (frequency-domain) HRTF of the
                    desired speaker’s DOA, and \( \hat{\tilde{\boldsymbol{s}}}_d \) represents the STFT of estimated
                    binaural desierd signal.
                </figcaption>
            </figure>

            <figure>
                <img src="assets/images/convention_1.png" alt="Measurement system" />
                <figcaption>
                    Figure 2: The simulation convention, illustrating an example with two concurrent speakers positioned
                    at \( \theta_1 = 40^\circ \) (left) and \( \theta_2 = -30^\circ \) (right), with a fixed
                    elevation \( \phi \). Images sourced from: https://www.freepik.com
                </figcaption>

            </figure>
        </div>
    </section>

    <section id="demos">
        <h2>Audio Examples and spectrograms</h2>

        <h4>Example from the From the WSJ0-CSR1 dataset in an anechoic — speaker 1 at -35°, speaker 2 at -90°</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_wsj/mix_0.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/anechoic_wsj/mix_0.wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_wsj/y_hat_1_0_az_tensor([325])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_wsj/y_hat_1_0_az_tensor([325])_elev_tensor([0]).wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_wsj/y_hat_2_0_az_tensor([270])_elev_tensor([-10]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_wsj/y_hat_2_0_az_tensor([270])_elev_tensor([-10]).wav"></audio>
                </div>
                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls src="assets/audio/anechoic_wsj/y1_0_az_tensor([325])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls
                        src="assets/audio/anechoic_wsj/y2_0_az_tensor([270])_elev_tensor([-10]).wav"></audio>
                </div>
            </div>

        </div>

        <h4>Example from the Librispeech dataset in an anechoic setting; speaker 1 at 20&deg; and speaker 2
            at
            80&deg;</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri/mix_0.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/anechoic_libri/mix_0.wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri/y_hat_1_0_az_tensor([20])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri/y_hat_1_0_az_tensor([20])_elev_tensor([0]).wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri/y_hat_2_0_az_tensor([80])_elev_tensor([0]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri/y_hat_2_0_az_tensor([80])_elev_tensor([0]).wav"></audio>

                </div>

                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls src="assets/audio/anechoic_libri/y1_0_az_tensor([20])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls src="assets/audio/anechoic_libri/y2_0_az_tensor([80])_elev_tensor([0]).wav"></audio>
                </div>
            </div>

        </div>

        <h4>Example from the Librispeech MLS French dataset in an anechoic setting; speaker 1 at 80&deg; and
            speaker 2 at 15&deg;</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri_fr/mix_472.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/anechoic_libri_fr/mix_472.wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri_fr/y_hat_1_472_az_tensor([80])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y_hat_1_472_az_tensor([80])_elev_tensor([0]).wav"></audio>
                </div>
                <div style="text-align: center;">
                    <img src="assets/images/anechoic_libri_fr/y_hat_2_472_az_tensor([15])_elev_tensor([10]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y_hat_2_472_az_tensor([15])_elev_tensor([10]).wav"></audio>

                </div>

                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y1_472_az_tensor([80])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls
                        src="assets/audio/anechoic_libri_fr/y2_472_az_tensor([15])_elev_tensor([10]).wav"></audio>
                </div>
            </div>


        </div>

        <h4>Example from the WSJ0-CSR1 dataset in a reverberant setting; speaker 1 at -25&deg; and
            speaker 2 at -75&deg;;</h4>
        <div class="spec-row">
            <div class="spec-images">
                <div style="text-align: center;">
                    <img src="assets/images/reverberant_wsj/mix_260.png" alt="Mixture spectrogram">
                    <audio controls src="assets/audio/reverberant_wsj/mix_260.wav"></audio>

                </div>

                <div style="text-align: center;">
                    <img src="assets/images/reverberant_wsj/y_hat_1_260_az_tensor([335])_elev_tensor([0]).png"
                        alt="Speaker 1 spectrogram">
                    <audio controls
                        src="assets/audio/reverberant_wsj/y_hat_1_260_az_tensor([335])_elev_tensor([0]).wav"></audio>

                </div>

                <div style="text-align: center;">
                    <img src="assets/images/reverberant_wsj/y_hat_2_260_az_tensor([285])_elev_tensor([-10]).png"
                        alt="Speaker 2 spectrogram">
                    <audio controls
                        src="assets/audio/reverberant_wsj/y_hat_2_260_az_tensor([285])_elev_tensor([-10]).wav"></audio>

                </div>

                <div class="demo-card">
                    <p><strong>Ground Truth Speaker 1:</strong></p>
                    <audio controls
                        src="assets/audio/reverberant_wsj/y1_260_az_tensor([335])_elev_tensor([0]).wav"></audio>

                    <p><strong>Ground Truth Speaker 2:</strong></p>
                    <audio controls
                        src="assets/audio/reverberant_wsj/y2_260_az_tensor([285])_elev_tensor([-10]).wav"></audio>
                </div>
            </div>
        </div>
    </section>
</body>

</html>